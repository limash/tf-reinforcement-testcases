{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading environment football failed: No module named 'gfootball'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "from kaggle_environments import make\n",
    "from tf_reinforcement_testcases import deep_q_learning, misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random policy reward is 22.0\n",
      "Untrained policy reward is 11.0\n"
     ]
    }
   ],
   "source": [
    "halite = 'gym_halite:halite-v0'\n",
    "cart_pole = \"CartPole-v1\"\n",
    "env_name = cart_pole\n",
    "agent = deep_q_learning.DoubleDuelingDQNAgent(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step: 200, reward: 9.333333333333334, eps: 0.100\n",
      "Time spend for sampling is 3.409385681152344e-05\n",
      "Time spend for training is 0.0004944801330566406\n",
      "Training step: 400, reward: 8.666666666666666, eps: 0.100\n",
      "Time spend for sampling is 0.001842498779296875\n",
      "Time spend for training is 0.0007481575012207031\n",
      "Training step: 600, reward: 9.0, eps: 0.100\n",
      "Time spend for sampling is 0.0013899803161621094\n",
      "Time spend for training is 0.0005211830139160156\n",
      "Training step: 800, reward: 9.333333333333334, eps: 0.100\n",
      "Time spend for sampling is 0.0012907981872558594\n",
      "Time spend for training is 0.00043272972106933594\n",
      "Training step: 1000, reward: 9.666666666666666, eps: 0.100\n",
      "Time spend for sampling is 0.0012981891632080078\n",
      "Time spend for training is 0.0004718303680419922\n",
      "Training step: 1200, reward: 42.0, eps: 0.100\n",
      "Time spend for sampling is 0.0012993812561035156\n",
      "Time spend for training is 0.00048661231994628906\n",
      "Training step: 1400, reward: 89.0, eps: 0.100\n",
      "Time spend for sampling is 0.0011103153228759766\n",
      "Time spend for training is 0.0005025863647460938\n",
      "Training step: 1600, reward: 10.333333333333334, eps: 0.100\n",
      "Time spend for sampling is 0.0013337135314941406\n",
      "Time spend for training is 0.0004487037658691406\n",
      "Training step: 1800, reward: 41.0, eps: 0.100\n",
      "Time spend for sampling is 0.0015387535095214844\n",
      "Time spend for training is 0.0005002021789550781\n",
      "Training step: 2000, reward: 11.666666666666666, eps: 0.100\n",
      "Time spend for sampling is 0.0012123584747314453\n",
      "Time spend for training is 0.0004334449768066406\n",
      "Training step: 2200, reward: 10.0, eps: 0.100\n",
      "Time spend for sampling is 0.00144195556640625\n",
      "Time spend for training is 0.0005745887756347656\n",
      "Training step: 2400, reward: 10.333333333333334, eps: 0.100\n",
      "Time spend for sampling is 0.0011997222900390625\n",
      "Time spend for training is 0.0005154609680175781\n",
      "Training step: 2600, reward: 20.333333333333332, eps: 0.100\n",
      "Time spend for sampling is 0.0012378692626953125\n",
      "Time spend for training is 0.0006091594696044922\n",
      "Training step: 2800, reward: 40.0, eps: 0.100\n",
      "Time spend for sampling is 0.0014503002166748047\n",
      "Time spend for training is 0.0005059242248535156\n",
      "Training step: 3000, reward: 94.33333333333333, eps: 0.100\n",
      "Time spend for sampling is 0.001680135726928711\n",
      "Time spend for training is 0.0005538463592529297\n",
      "Training step: 3200, reward: 10.333333333333334, eps: 0.100\n",
      "Time spend for sampling is 0.0015766620635986328\n",
      "Time spend for training is 0.0005249977111816406\n",
      "Training step: 3400, reward: 59.666666666666664, eps: 0.100\n",
      "Time spend for sampling is 0.0015964508056640625\n",
      "Time spend for training is 0.0008473396301269531\n",
      "Training step: 3600, reward: 73.0, eps: 0.100\n",
      "Time spend for sampling is 0.0015337467193603516\n",
      "Time spend for training is 0.0006184577941894531\n",
      "Training step: 3800, reward: 104.66666666666667, eps: 0.100\n",
      "Time spend for sampling is 4.00543212890625e-05\n",
      "Time spend for training is 0.0005223751068115234\n",
      "Training step: 4000, reward: 36.0, eps: 0.100\n",
      "Time spend for sampling is 0.001790761947631836\n",
      "Time spend for training is 0.0007927417755126953\n",
      "Training step: 4200, reward: 32.0, eps: 0.100\n",
      "Time spend for sampling is 0.0011818408966064453\n",
      "Time spend for training is 0.0005204677581787109\n",
      "Training step: 4400, reward: 94.66666666666667, eps: 0.100\n",
      "Time spend for sampling is 0.0015110969543457031\n",
      "Time spend for training is 0.0007493495941162109\n",
      "Training step: 4600, reward: 115.33333333333333, eps: 0.100\n",
      "Time spend for sampling is 0.0011630058288574219\n",
      "Time spend for training is 0.0005173683166503906\n",
      "Training step: 4800, reward: 127.66666666666667, eps: 0.100\n",
      "Time spend for sampling is 0.0011076927185058594\n",
      "Time spend for training is 0.0004942417144775391\n",
      "Training step: 5000, reward: 72.66666666666667, eps: 0.100\n",
      "Time spend for sampling is 0.0016982555389404297\n",
      "Time spend for training is 0.0006020069122314453\n",
      "Training step: 5200, reward: 158.33333333333334, eps: 0.100\n",
      "Time spend for sampling is 0.0020580291748046875\n",
      "Time spend for training is 0.0007312297821044922\n",
      "Training step: 5400, reward: 147.33333333333334, eps: 0.100\n",
      "Time spend for sampling is 0.0017917156219482422\n",
      "Time spend for training is 0.0007188320159912109\n",
      "Training step: 5600, reward: 97.0, eps: 0.100\n",
      "Time spend for sampling is 0.0011970996856689453\n",
      "Time spend for training is 0.0004875659942626953\n",
      "Training step: 5800, reward: 12.666666666666666, eps: 0.100\n",
      "Time spend for sampling is 0.0010483264923095703\n",
      "Time spend for training is 0.0004303455352783203\n",
      "Training step: 6000, reward: 113.0, eps: 0.100\n",
      "Time spend for sampling is 0.0015091896057128906\n",
      "Time spend for training is 0.0005068778991699219\n",
      "Training step: 6200, reward: 252.33333333333334, eps: 0.100\n",
      "Time spend for sampling is 4.6253204345703125e-05\n",
      "Time spend for training is 0.0005564689636230469\n",
      "Training step: 6400, reward: 147.66666666666666, eps: 0.100\n",
      "Time spend for sampling is 0.0018768310546875\n",
      "Time spend for training is 0.0007760524749755859\n",
      "Training step: 6600, reward: 188.0, eps: 0.100\n",
      "Time spend for sampling is 0.0011701583862304688\n",
      "Time spend for training is 0.000579833984375\n",
      "Training step: 6800, reward: 163.0, eps: 0.100\n",
      "Time spend for sampling is 0.0011494159698486328\n",
      "Time spend for training is 0.0005979537963867188\n",
      "Training step: 7000, reward: 371.6666666666667, eps: 0.100\n",
      "Time spend for sampling is 3.409385681152344e-05\n",
      "Time spend for training is 0.0005021095275878906\n",
      "Training step: 7200, reward: 204.33333333333334, eps: 0.100\n",
      "Time spend for sampling is 0.0011415481567382812\n",
      "Time spend for training is 0.0004668235778808594\n",
      "Training step: 7400, reward: 246.33333333333334, eps: 0.100\n",
      "Time spend for sampling is 0.0014996528625488281\n",
      "Time spend for training is 0.0005161762237548828\n",
      "Training step: 7600, reward: 225.33333333333334, eps: 0.100\n",
      "Time spend for sampling is 0.0011763572692871094\n",
      "Time spend for training is 0.0006010532379150391\n",
      "Training step: 7800, reward: 309.3333333333333, eps: 0.100\n",
      "Time spend for sampling is 0.0013167858123779297\n",
      "Time spend for training is 0.0005271434783935547\n",
      "Training step: 8000, reward: 338.3333333333333, eps: 0.100\n",
      "Time spend for sampling is 0.001440286636352539\n",
      "Time spend for training is 0.0004322528839111328\n",
      "Training step: 8200, reward: 235.66666666666666, eps: 0.100\n",
      "Time spend for sampling is 0.0013570785522460938\n",
      "Time spend for training is 0.0004849433898925781\n",
      "Training step: 8400, reward: 259.0, eps: 0.100\n",
      "Time spend for sampling is 0.001401662826538086\n",
      "Time spend for training is 0.0005121231079101562\n",
      "Training step: 8600, reward: 182.66666666666666, eps: 0.100\n",
      "Time spend for sampling is 0.0013415813446044922\n",
      "Time spend for training is 0.0005249977111816406\n",
      "Training step: 8800, reward: 260.6666666666667, eps: 0.100\n",
      "Time spend for sampling is 0.0015282630920410156\n",
      "Time spend for training is 0.0005116462707519531\n",
      "Training step: 9000, reward: 193.66666666666666, eps: 0.100\n",
      "Time spend for sampling is 0.0014214515686035156\n",
      "Time spend for training is 0.0006201267242431641\n",
      "Training step: 9200, reward: 224.0, eps: 0.100\n",
      "Time spend for sampling is 0.0012645721435546875\n",
      "Time spend for training is 0.0006477832794189453\n",
      "Training step: 9400, reward: 166.0, eps: 0.100\n",
      "Time spend for sampling is 0.0015566349029541016\n",
      "Time spend for training is 0.0005393028259277344\n",
      "Training step: 9600, reward: 186.0, eps: 0.100\n",
      "Time spend for sampling is 0.0023369789123535156\n",
      "Time spend for training is 0.0008001327514648438\n",
      "Training step: 9800, reward: 142.0, eps: 0.100\n",
      "Time spend for sampling is 0.0015106201171875\n",
      "Time spend for training is 0.0005371570587158203\n",
      "Training step: 10000, reward: 166.0, eps: 0.100\n",
      "Time spend for sampling is 0.001451730728149414\n",
      "Time spend for training is 0.00040411949157714844\n"
     ]
    }
   ],
   "source": [
    "model = agent.train(iterations_number=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if env_name == cart_pole:\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    observation = env.reset()\n",
    "    for _ in range(1000):\n",
    "        env.render()\n",
    "        action = model(observation[np.newaxis, :])\n",
    "        observation, reward, done, info = env.step(np.argmax(action.numpy()))\n",
    "\n",
    "        if done:\n",
    "            observation = env.reset()\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if env_name == halite:\n",
    "    halite_agent = misc.get_halite_agent(model)\n",
    "    # these are the settings used for a halite v0.1\n",
    "    board_size = 5\n",
    "    starting_halite = 5000\n",
    "\n",
    "    env = make(\"halite\",\n",
    "               configuration={\"size\": board_size,\n",
    "                              \"startingHalite\": starting_halite},\n",
    "               debug=True)\n",
    "    env.run([halite_agent])\n",
    "    env.render(mode=\"ipython\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
